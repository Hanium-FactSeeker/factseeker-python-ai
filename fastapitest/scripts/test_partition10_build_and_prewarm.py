# test_partition10_build_and_prewarm.py
# -*- coding: utf-8 -*-
import os
import re
import glob
import time
import shutil
import logging
import warnings
import subprocess
from typing import List, Optional

import boto3
import pandas as pd
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.docstore.document import Document

from webdriver_manager.chrome import ChromeDriverManager
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.keys import Keys

TARGET_PARTITION = "partition_10"
REQUIRED_CSV_COLUMNS = ["ì¼ì", "ì–¸ë¡ ì‚¬", "ì œëª©", "URL", "íŠ¹ì„±ì¶”ì¶œ(ê°€ì¤‘ì¹˜ìˆœ ìƒìœ„ 50ê°œ)"]


# -------------------------------
# Filesystem helpers
# -------------------------------
def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def wait_for_download_complete(download_dir: str, timeout_sec: int = 600) -> str:
    """í¬ë¡¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°(.crdownload ì—†ì–´ì§ˆ ë•Œê¹Œì§€), ì—‘ì…€/CSV í™•ì¥ì íŒŒì¼ì´ ë³´ì´ë©´ ê²½ë¡œ ë°˜í™˜."""
    ensure_dir(download_dir)
    start = time.time()
    last_file: Optional[str] = None
    while time.time() - start < timeout_sec:
        partials = glob.glob(os.path.join(download_dir, "*.crdownload"))
        if not partials:
            files = [p for p in glob.glob(os.path.join(download_dir, "*")) if os.path.isfile(p)]
            if files:
                files.sort(key=os.path.getmtime, reverse=True)
                last_file = files[0]
                ext = os.path.splitext(last_file)[1].lower()
                if ext in (".xlsx", ".xls", ".csv"):
                    return last_file
        time.sleep(1)
    raise TimeoutError(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (last={last_file})")


# -------------------------------
# Selenium utils
# -------------------------------
def _accept_unexpected_alerts(driver, wait_timeout: float = 1.0) -> Optional[str]:
    """ì˜ˆìƒì¹˜ ëª»í•œ alertì´ ë– ìˆìœ¼ë©´ OKë¡œ ë‹«ê³  í…ìŠ¤íŠ¸ ë°˜í™˜."""
    try:
        WebDriverWait(driver, wait_timeout).until(EC.alert_is_present())
        al = driver.switch_to.alert
        txt = al.text
        al.accept()
        return txt
    except TimeoutException:
        return None


def _scroll_into_view(driver, el):
    try:
        driver.execute_script("arguments[0].scrollIntoView({block:'center', inline:'center'});", el)
    except Exception:
        pass


def _open_step_panel(driver, panel_id: str):
    """ì£¼ì–´ì§„ íŒ¨ë„(#collapse-step-X)ì´ ì ‘í˜€ ìˆìœ¼ë©´ í¼ì¹œë‹¤."""
    try:
        btn = driver.find_element(By.ID, panel_id)
        expanded = (btn.get_attribute("aria-expanded") or "").lower()
        if expanded in ("", "false"):
            driver.execute_script("arguments[0].click();", btn)
            time.sleep(0.3)
    except Exception:
        pass


def _open_tab(driver, css_selector: str):
    """íƒ­ a[href='#srch-tabX']ë¥¼ í´ë¦­."""
    try:
        tab = WebDriverWait(driver, 7).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector)))
        driver.execute_script("arguments[0].click();", tab)
        time.sleep(0.2)
    except Exception:
        pass


# -------------------------------
# Media (ì–¸ë¡ ì‚¬) & Category (í†µí•©ë¶„ë¥˜)
# -------------------------------
def select_national_dailies(driver, wait):
    """ì–¸ë¡ ì‚¬ íƒ­ì—ì„œ 'ì „êµ­ì¼ê°„ì§€'ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì²´í¬."""
    logging.info("ğŸ“° ì–¸ë¡ ì‚¬ íƒ­ ì§„ì… ë° 'ì „êµ­ì¼ê°„ì§€' ì„ íƒ ì‹œë„")
    _open_tab(driver, "a[href='#srch-tab2']")
    time.sleep(0.5)

    # ì¼ë¶€ ë ˆì´ì•„ì›ƒì—ì„œ ë¨¼ì € 'ë°©ì†¡ì‚¬'ë¥¼ ëˆŒëŸ¬ì•¼ ë‹¤ë¥¸ ì˜µì…˜ì´ í™œì„±í™”ë¨
    try:
        b = driver.find_element(By.ID, "ë°©ì†¡ì‚¬")
        _scroll_into_view(driver, b)
        b.click()
        time.sleep(0.2)
    except Exception:
        pass

    # IDë¡œ ì§ì ‘ í´ë¦­ â†’ ì‹¤íŒ¨ ì‹œ ë¼ë²¨/fallback XPATH
    try:
        wait.until(EC.presence_of_element_located((By.ID, 'ì „êµ­ì¼ê°„ì§€')))
        driver.execute_script("document.getElementById('ì „êµ­ì¼ê°„ì§€').click();")
        time.sleep(0.2)
        return
    except Exception:
        pass

    try:
        lbl = driver.find_element(By.CSS_SELECTOR, "label[for='ì „êµ­ì¼ê°„ì§€']")
        _scroll_into_view(driver, lbl)
        driver.execute_script("arguments[0].click();", lbl)
        time.sleep(0.2)
        return
    except Exception:
        pass

    try:
        node = driver.find_element(By.XPATH, "//*[contains(normalize-space(.), 'ì „êµ­ì¼ê°„ì§€')]")
        _scroll_into_view(driver, node)
        driver.execute_script("arguments[0].click();", node)
        time.sleep(0.2)
    except Exception:
        logging.warning("âš ï¸ ì „êµ­ì¼ê°„ì§€ ì„ íƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")


def choose_politics_category(driver, wait):
    """í†µí•©ë¶„ë¥˜ íƒ­ì—ì„œ 'ì •ì¹˜' ì„ íƒ."""
    logging.info("ğŸ·ï¸ í†µí•©ë¶„ë¥˜ íƒ­ ì§„ì… ë° 'ì •ì¹˜' ì„ íƒ ì‹œë„")
    _open_tab(driver, "a[href='#srch-tab3']")
    time.sleep(0.3)
    try:
        node = wait.until(EC.element_to_be_clickable((By.XPATH, '//span[@data-role="display" and text()="ì •ì¹˜"]')))
        _scroll_into_view(driver, node)
        node.click()
        time.sleep(0.2)
    except Exception:
        logging.warning("âš ï¸ í†µí•©ë¶„ë¥˜ 'ì •ì¹˜' ì„ íƒ ì‹¤íŒ¨. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")


# -------------------------------
# Date input
# -------------------------------
def _ensure_date_direct_input_mode(driver) -> None:
    """ê¸°ê°„ ì…ë ¥ì„ 'ì§ì ‘ì…ë ¥/ì‚¬ìš©ì ì§€ì •' ëª¨ë“œë¡œ ì „í™˜ ì‹œë„."""
    js = r'''
    return (function(){
      function clickNode(n){
        try{ n.scrollIntoView({block:'center'}); n.click(); return true; }catch(e){ return false; }
      }
      const labels = ['ì§ì ‘ì…ë ¥','ì‚¬ìš©ì ì§€ì •','ìˆ˜ë™ì…ë ¥','ìˆ˜ë™','ì§ì ‘'];
      for (const t of labels){
        const nodes = Array.from(document.querySelectorAll('label,button,a,span,div'));
        for (const n of nodes){
          const s = (n.innerText||'').replace(/\s+/g,' ').trim();
          if (s && s.includes(t)) { if (clickNode(n)) return 'text'; }
        }
      }
      const radios = Array.from(document.querySelectorAll('input[type=radio],input[type=button]'));
      for (const r of radios){
        const s = ((r.id||'')+' '+(r.value||'')+' '+(r.name||'')).toLowerCase();
        if (/(direct|manual|custom|user|free)/.test(s)){
          if (clickNode(r)) return 'radio';
        }
      }
      return '';
    })();
    '''
    try:
        mode = driver.execute_script(js)
        if mode:
            time.sleep(0.2)
    except Exception:
        pass


def set_date_range_with_events(driver, start_str: str, end_str: str):
    js = r'''
    (function(){
      function setAndDispatch(id, val){
        var el = document.getElementById(id);
        if(!el){return;}
        try { el.removeAttribute('readonly'); } catch(_){}
        el.value = val;
        if (window.jQuery){
          try { window.jQuery(el).val(val).trigger('input').trigger('change'); } catch(_){}
        }
        el.dispatchEvent(new Event('input', {bubbles:true}));
        el.dispatchEvent(new Event('change', {bubbles:true}));
      }
      setAndDispatch('search-begin-date', arguments[0]);
      setAndDispatch('search-end-date', arguments[1]);
    })();
    '''
    driver.execute_script(js, start_str, end_str)


def set_date_range_robust(driver, start_str: str, end_str: str, retries: int = 3) -> None:
    """
    ë‚ ì§œ ì…ë ¥ì„ ìµœëŒ€í•œ í™•ì‹¤í•˜ê²Œ ì ìš©í•œë‹¤.
    - STEP1 íŒ¨ë„ ê°•ì œ ì˜¤í”ˆ
    - ì§ì ‘ì…ë ¥ ëª¨ë“œ ì „í™˜
    - readonly ì œê±° í›„ ê°’ ì£¼ì… + ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
    - í´ë°±ìœ¼ë¡œ í‚¤ë³´ë“œ ì…ë ¥
    - ì•ŒëŸ¿ ë°œìƒ ì‹œ ìë™ ìˆ˜ë½ í›„ ì¬ì‹œë„
    """
    def norm(d: str) -> str:
        m = re.match(r"^(\d{4})-(\d{1,2})-(\d{1,2})$", d)
        if not m:
            return d
        y, mo, da = m.groups()
        return f"{y}-{int(mo):02d}-{int(da):02d}"

    start_str = norm(start_str)
    end_str = norm(end_str)

    if not re.match(r"^\d{4}-\d{2}-\d{2}$", start_str) or not re.match(r"^\d{4}-\d{2}-\d{2}$", end_str):
        raise ValueError(f"ë‚ ì§œ í˜•ì‹ì€ YYYY-MM-DD ì´ì–´ì•¼ í•©ë‹ˆë‹¤. start={start_str}, end={end_str}")

    logging.info(f"ğŸ“… ê¸°ê°„ ì„¤ì • ì‹œë„: {start_str} ~ {end_str}")
    # STEP1 í™•ë³´ + ì§ì ‘ì…ë ¥ ëª¨ë“œ
    _open_tab(driver, "a[href='#srch-tab1']")
    _open_step_panel(driver, "collapse-step-1")
    _ensure_date_direct_input_mode(driver)

    for attempt in range(1, retries + 1):
        # A. JS ì£¼ì… + ì´ë²¤íŠ¸
        try:
            js = r'''
            (function(s,e){
              function setVal(id, val){
                var el = document.getElementById(id);
                if(!el) return false;
                try { el.removeAttribute('readonly'); } catch(_){}
                el.value = val;
                if (window.jQuery){
                  try { window.jQuery(el).val(val).trigger('input').trigger('change'); } catch(_){}
                }
                el.dispatchEvent(new Event('input', {bubbles:true}));
                el.dispatchEvent(new Event('change', {bubbles:true}));
                return true;
              }
              var ok1 = setVal('search-begin-date', s);
              var ok2 = setVal('search-end-date', e);
              document.activeElement && document.activeElement.blur && document.activeElement.blur();
              document.body && document.body.click && document.body.click();
              return ok1 && ok2;
            })(arguments[0], arguments[1]);
            '''
            driver.execute_script(js, start_str, end_str)
        except Exception:
            pass

        time.sleep(0.5)
        _accept_unexpected_alerts(driver, wait_timeout=0.7)

        begin_val, end_val = driver.execute_script(
            "return [document.getElementById('search-begin-date')?.value, document.getElementById('search-end-date')?.value];"
        )
        if begin_val == start_str and end_val == end_str:
            return

        # B. í´ë°±: í‚¤ë³´ë“œ ì…ë ¥
        try:
            b = driver.find_element(By.ID, 'search-begin-date')
            e = driver.find_element(By.ID, 'search-end-date')
            for el, val in ((b, start_str), (e, end_str)):
                driver.execute_script("arguments[0].removeAttribute('readonly');", el)
                _scroll_into_view(driver, el)
                el.click(); time.sleep(0.05)
                el.send_keys(Keys.CONTROL, 'a'); time.sleep(0.05)
                el.send_keys(val); time.sleep(0.05)
                el.send_keys(Keys.TAB)
            time.sleep(0.5)
            _accept_unexpected_alerts(driver, wait_timeout=0.7)
            begin_val, end_val = driver.execute_script(
                "return [document.getElementById('search-begin-date')?.value, document.getElementById('search-end-date')?.value];"
            )
            if begin_val == start_str and end_val == end_str:
                return
        except Exception:
            pass

        logging.info(f"âŸ³ ë‚ ì§œ ì¬ì‹œë„ í•„ìš”(ì‹œë„ {attempt}/{retries}): begin={begin_val}, end={end_val}")
        time.sleep(0.4)

    # ë§ˆì§€ë§‰ ì‹œë„
    set_date_range_with_events(driver, start_str, end_str)
    time.sleep(0.4)
    _accept_unexpected_alerts(driver, wait_timeout=0.7)


# -------------------------------
# ë¶„ì„ê¸°ì‚¬ í•„í„°
# -------------------------------
def apply_analysis_article_filter(driver, wait, max_retry: int = 3) -> bool:
    """'ë¶„ì„ê¸°ì‚¬' ì²´í¬ í›„ 'ì ìš©í•˜ê¸°'ê¹Œì§€ ì‹ ë¢°ì„± ìˆê²Œ ìˆ˜í–‰."""
    logging.info("ğŸ§© 'ë¶„ì„ê¸°ì‚¬' ì²´í¬ ë° 'ì ìš©í•˜ê¸°' ìˆ˜í–‰")
    _open_step_panel(driver, "collapse-step-2")  # í•„í„°/ì¡°ê±´ íŒ¨ë„

    for i in range(1, max_retry + 1):
        try:
            cb = WebDriverWait(driver, 7).until(EC.presence_of_element_located((By.ID, "filter-tm-use")))
            _scroll_into_view(driver, cb)

            # 1) ë¼ë²¨ ìš°ì„  í´ë¦­
            try:
                label = driver.find_element(By.CSS_SELECTOR, "label[for='filter-tm-use']")
                _scroll_into_view(driver, label)
                driver.execute_script("arguments[0].click();", label)
                time.sleep(0.2)
            except Exception:
                pass

            # 2) ì²´í¬ ìƒíƒœ ê°•ì œ + ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
            is_checked = driver.execute_script("return !!document.getElementById('filter-tm-use')?.checked;")
            if not is_checked:
                js_force = r'''
                (function(){
                  var el = document.getElementById('filter-tm-use');
                  if(!el) return false;
                  el.checked = true;
                  el.dispatchEvent(new Event('click', {bubbles:true}));
                  el.dispatchEvent(new Event('input', {bubbles:true}));
                  el.dispatchEvent(new Event('change', {bubbles:true}));
                  return el.checked === true;
                })();
                '''
                is_checked = driver.execute_script(js_force)
                time.sleep(0.2)

            if not is_checked:
                # ë§ˆì§€ë§‰ ì‹œë„: ì²´í¬ë°•ìŠ¤ ë³¸ì²´ í´ë¦­
                try:
                    _scroll_into_view(driver, cb)
                    cb.click()
                    time.sleep(0.2)
                    is_checked = driver.execute_script("return !!document.getElementById('filter-tm-use')?.checked;")
                except Exception:
                    pass

            if not is_checked:
                logging.warning(f"âš ï¸ ë¶„ì„ê¸°ì‚¬ ì²´í¬ ì‹¤íŒ¨(ì‹œë„ {i}/{max_retry}) - ë‹¤ì‹œ ì‹œë„")
                _accept_unexpected_alerts(driver, wait_timeout=0.5)
                continue

            # 3) 'ì ìš©í•˜ê¸°' ë²„íŠ¼ í´ë¦­ (ë‹¤ì¤‘ ì…€ë ‰í„°)
            apply_candidates = [
                (By.XPATH, "//button[contains(normalize-space(.), 'ì ìš©í•˜ê¸°')]"),
                (By.XPATH, "//a[contains(normalize-space(.), 'ì ìš©í•˜ê¸°')]"),
                (By.CSS_SELECTOR, "button.btn-apply"),
                (By.CSS_SELECTOR, "button.apply"),
                (By.CSS_SELECTOR, "button.filter-apply"),
            ]
            applied = False
            for by, sel in apply_candidates:
                try:
                    btn = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((by, sel)))
                    _scroll_into_view(driver, btn)
                    driver.execute_script("arguments[0].click();", btn)
                    applied = True
                    break
                except Exception:
                    continue

            if not applied:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: í…ìŠ¤íŠ¸ í¬í•¨ ì„ì˜ ë²„íŠ¼ íƒìƒ‰
                try:
                    btn = driver.find_element(By.XPATH, "//button[contains(., 'ì ìš©í•˜ê¸°') or contains(., 'ì ìš©')]")
                    _scroll_into_view(driver, btn)
                    driver.execute_script("arguments[0].click();", btn)
                    applied = True
                except Exception:
                    pass

            if not applied:
                logging.warning(f"âš ï¸ ì ìš©í•˜ê¸° ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨(ì‹œë„ {i}/{max_retry})")
                _accept_unexpected_alerts(driver, wait_timeout=0.5)
                continue

            _accept_unexpected_alerts(driver, wait_timeout=1.0)
            time.sleep(1.2)

            still_checked = driver.execute_script("return !!document.getElementById('filter-tm-use')?.checked;")
            logging.info("âœ… ë¶„ì„ê¸°ì‚¬ ì²´í¬ ë° ì ìš©í•˜ê¸° ì™„ë£Œ (checked=%s)", still_checked)
            return True

        except Exception as e:
            logging.warning(f"âš ï¸ ë¶„ì„ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸(ì‹œë„ {i}/{max_retry}): {e}")
            _accept_unexpected_alerts(driver, wait_timeout=0.8)
            try:
                driver.save_screenshot(f"error_filter_try{i}.png")
            except Exception:
                pass
            time.sleep(0.6)

    return False


# -------------------------------
# Overlays & Search button
# -------------------------------
def _is_visible(driver, el) -> bool:
    try:
        if not el.is_displayed():
            return False
        rect = driver.execute_script(
            "var r=arguments[0].getBoundingClientRect(); return [r.width,r.height];", el
        )
        return (rect[0] > 0 and rect[1] > 0)
    except Exception:
        return False


def _dismiss_common_overlays(driver):
    """ì¿ í‚¤/ëª¨ë‹¬/ë ˆì´ì–´ íŒì—… ë‹«ê¸° ì‹œë„."""
    try:
        texts = ["í™•ì¸", "ë™ì˜", "ë™ì˜í•©ë‹ˆë‹¤", "ë‹«ê¸°", "ì˜¤ëŠ˜ ê·¸ë§Œ ë³´ê¸°", "X", "ë‹«  ê¸°"]
        candidates = driver.find_elements(
            By.XPATH,
            "//*[contains(@class,'modal') or contains(@class,'layer') or contains(@class,'popup') or contains(@class,'overlay') or contains(@class,'dim')]//button|//a"
        )
        for btn in candidates:
            label = (btn.text or "").strip()
            if any(t in label for t in texts):
                try:
                    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btn)
                    driver.execute_script("arguments[0].click();", btn)
                    time.sleep(0.2)
                except Exception:
                    pass
    except Exception:
        pass


def click_search_button(driver, wait, max_retry: int = 2):
    """
    BigKinds í˜ì´ì§€ì—ì„œ 'ê²€ìƒ‰í•˜ê¸°'ë¥¼ í™•ì‹¤íˆ ëˆ„ë¥¸ë‹¤.
    - ì˜¤ë²„ë ˆì´/ì¿ í‚¤ íŒì—… ë‹«ê¸°
    - ë‹¤ì¤‘ ì…€ë ‰í„° íƒìƒ‰
    - JS í´ë¦­ í´ë°±
    """
    _dismiss_common_overlays(driver)

    selectors = [
        (By.CSS_SELECTOR, "button.news-report-search-btn"),
        (By.CSS_SELECTOR, "button.news-search-btn"),
        (By.CSS_SELECTOR, "button.btn-search"),
        (By.XPATH, "//button[contains(normalize-space(.),'ê²€ìƒ‰í•˜ê¸°')]"),
        (By.XPATH, "//a[contains(normalize-space(.),'ê²€ìƒ‰í•˜ê¸°')]"),
        (By.XPATH, "//button[contains(.,'ê²€ìƒ‰')]"),
        (By.XPATH, "//a.contains(.,'ê²€ìƒ‰')]"),
        (By.CSS_SELECTOR, "button[class*='search']"),
    ]

    for attempt in range(1, max_retry + 1):
        logging.info(f"ğŸ” ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì‹œë„ {attempt}/{max_retry}")
        _dismiss_common_overlays(driver)
        for by, sel in selectors:
            try:
                el = wait.until(EC.presence_of_element_located((by, sel)))
                if not _is_visible(driver, el):
                    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", el)
                    time.sleep(0.1)
                try:
                    el = wait.until(EC.element_to_be_clickable((by, sel)))
                    ActionChains(driver).move_to_element(el).pause(0.05).click().perform()
                except Exception:
                    driver.execute_script("arguments[0].click();", el)
                time.sleep(0.3)
                return True
            except Exception:
                continue

        # ì—”í„°í‚¤ í´ë°±
        try:
            driver.find_element(By.TAG_NAME, "body").send_keys(Keys.ENTER)
            time.sleep(0.3)
            return True
        except Exception:
            pass

        time.sleep(0.4)

    raise TimeoutException("ê²€ìƒ‰ ë²„íŠ¼ì„ ì°¾ê±°ë‚˜ í´ë¦­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


# -------------------------------
# Driver setup
# -------------------------------
def setup_driver(download_dir: str, headless: bool) -> tuple[webdriver.Chrome, WebDriverWait]:
    opts = Options()
    prefs = {
        "download.default_directory": os.path.abspath(download_dir),
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        "safebrowsing.enabled": True,
        "profile.default_content_settings.popups": 0,
    }
    opts.add_experimental_option("prefs", prefs)

    # ì¡ìŒ ë¡œê·¸ ì–µì œ (DEPRECATED_ENDPOINT ë“±)
    opts.add_experimental_option("excludeSwitches", ["enable-logging"])
    opts.add_argument("--log-level=3")
    opts.add_argument("--window-size=1400,900")
    # ë°ìŠ¤í¬í†± UA ê³ ì •(í—¤ë“œë¦¬ìŠ¤ ëª¨ë°”ì¼ ë ˆì´ì•„ì›ƒ íšŒí”¼)
    opts.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36")

    if headless:
        opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--disable-gpu")

    logging.info("ğŸ§© WebDriver ì´ˆê¸°í™” (headless=%s, download_dir=%s)", headless, os.path.abspath(download_dir))
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=opts)
    wait = WebDriverWait(driver, 15)
    return driver, wait


# -------------------------------
# BigKinds flow
# -------------------------------
def download_bigkinds_range(user_id: str, user_pw: str, start_date: str, end_date: str, download_dir: str, headless: bool = True) -> str:
    """ì§€ì • ë‚ ì§œ ë²”ìœ„(YYYY-MM-DD ~ YYYY-MM-DD)ë¡œ BigKinds ì—‘ì…€ ë‹¤ìš´ë¡œë“œ."""
    logging.info("ğŸš€ BigKinds ìˆ˜ì§‘ ì‹œì‘: %s ~ %s", start_date, end_date)
    driver, wait = setup_driver(download_dir, headless=headless)
    try:
        # 1) ì ‘ì† + ë¡œê·¸ì¸
        driver.get("https://www.bigkinds.or.kr")
        time.sleep(2)
        membership = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, "li.topMembership")))
        ActionChains(driver).move_to_element(membership).perform()
        time.sleep(0.6)
        login_link = wait.until(EC.element_to_be_clickable((By.XPATH, '//a[text()="ë¡œê·¸ì¸"]')))
        driver.execute_script("arguments[0].click();", login_link)
        wait.until(EC.visibility_of_element_located((By.ID, "login-user-id"))).send_keys(user_id)
        driver.find_element(By.ID, "login-user-password").send_keys(user_pw)
        wait.until(EC.element_to_be_clickable((By.ID, "login-btn"))).click()
        time.sleep(3)

        # 2) ë‰´ìŠ¤ ê²€ìƒ‰ í˜ì´ì§€
        driver.get("https://www.bigkinds.or.kr/v2/news/index.do")
        time.sleep(2)

        # 3) ì–¸ë¡ ì‚¬: ì „êµ­ì¼ê°„ì§€
        select_national_dailies(driver, wait)

        # 4) í†µí•©ë¶„ë¥˜: ì •ì¹˜
        choose_politics_category(driver, wait)

        # 5) ê¸°ê°„: ì§ì ‘ ë‚ ì§œ ì…ë ¥
        set_date_range_robust(driver, start_date, end_date)
        time.sleep(0.6)

        # 6) ê²€ìƒ‰ ì ìš© (ê²€ìƒ‰í•˜ê¸°)
        click_search_button(driver, wait)
        time.sleep(3)

        # 7) ë¶„ì„ê¸°ì‚¬ ì²´í¬ â†’ 'ì ìš©í•˜ê¸°'ê¹Œì§€
        ok_tm = apply_analysis_article_filter(driver, wait, max_retry=3)
        if not ok_tm:
            logging.warning("ë¶„ì„ê¸°ì‚¬ ì²´í¬/ì ìš© ë³´ì¥ ì‹¤íŒ¨ (ì§„í–‰ì€ ê³„ì†)")

        # 8) STEP3 ì—´ê³  ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
        _open_step_panel(driver, "collapse-step-3")
        time.sleep(0.4)
        excel_btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.news-download-btn.mobile-excel-download')))
        _scroll_into_view(driver, excel_btn)
        ActionChains(driver).move_to_element(excel_btn).click().perform()

        # 9) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
        path = wait_for_download_complete(download_dir)
        logging.info("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: %s", path)
        return path

    finally:
        try:
            driver.quit()
        except Exception:
            pass


# -------------------------------
# FAISS partition build/upload
# -------------------------------
def build_and_upload_partition10(df: pd.DataFrame, embeddings: OpenAIEmbeddings, bucket: str, s3_prefix_base: str) -> List[str]:
    logging.info("ğŸ§± íŒŒí‹°ì…˜ ë¹Œë“œ/ì—…ë¡œë“œ ì‹œì‘ (bucket=%s, prefix=%s)", bucket, s3_prefix_base)
    s3 = boto3.client("s3")
    part_name = TARGET_PARTITION
    s3_part_prefix = f"{s3_prefix_base.rstrip('/')}/{part_name}"
    work_dir = os.path.abspath(os.path.join(".tmp", part_name))
    if os.path.isdir(work_dir):
        shutil.rmtree(work_dir, ignore_errors=True)
    ensure_dir(work_dir)

    # ê¸°ì¡´ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°(ìˆìœ¼ë©´)
    resp = s3.list_objects_v2(Bucket=bucket, Prefix=f"{s3_part_prefix}/")
    if resp.get("Contents"):
        for obj in resp["Contents"]:
            key = obj["Key"]
            if key.endswith("index.faiss") or key.endswith("index.pkl"):
                dst = os.path.join(work_dir, os.path.basename(key))
                s3.download_file(bucket, key, dst)

    # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
    try:
        db = FAISS.load_local(work_dir, embeddings=embeddings, allow_dangerous_deserialization=True)
    except Exception:
        db = None

    # ì»¬ëŸ¼ ì‹ë³„
    df = df.copy()
    df.columns = [str(c).strip().replace("\n", "") for c in df.columns]
    logging.info("ğŸ—‚ï¸ ì…ë ¥ ë°ì´í„° ì»¬ëŸ¼: %s", df.columns.tolist())
    title_candidates = ["ì œëª©", "ê¸°ì‚¬ì œëª©", "title", "Title"]
    url_candidates = ["URL", "ì›ë¬¸URL", "url", "ë§í¬", "link", "Link"]
    tcol = next((c for c in df.columns if c in title_candidates), None)
    ucol = next((c for c in df.columns if c in url_candidates), None)
    if not tcol or not ucol:
        raise ValueError(f"ì œëª©/URL ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ë“¤: {list(df.columns)}")

    existing = set()
    if db:
        for d in db.docstore._dict.values():
            u = (d.metadata or {}).get("url")
            if isinstance(u, str):
                existing.add(u.strip())

    docs: List[Document] = []
    used_urls: List[str] = []
    seen = set()
    for _, row in df.iterrows():
        title = str(row.get(tcol, "")).strip()
        url = str(row.get(ucol, "")).strip()
        if not title or not re.match(r"^https?://", url):
            continue
        if url in existing or url in seen:
            continue
        seen.add(url)
        docs.append(Document(page_content=title, metadata={"url": url}))
        used_urls.append(url)

    logging.info("ğŸ”¢ ì‹ ê·œ ë¬¸ì„œ ìˆ˜: %d (ê¸°ì¡´:%d)", len(docs), len(existing))
    if db and docs:
        new_db = FAISS.from_documents(docs, embeddings)
        db.merge_from(new_db)
        db.save_local(work_dir)
    elif not db and docs:
        db = FAISS.from_documents(docs, embeddings)
        db.save_local(work_dir)
    elif not db and not docs:
        logging.info("ì‹ ê·œ ì¶”ê°€ ë¬¸ì„œê°€ ì—†ì–´ ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")

    # ì—…ë¡œë“œ ìˆœì„œ: pkl â†’ faiss
    if os.path.exists(os.path.join(work_dir, "index.pkl")) and os.path.exists(os.path.join(work_dir, "index.faiss")):
        for name in ("index.pkl", "index.faiss"):
            boto3.client("s3").upload_file(os.path.join(work_dir, name), bucket, f"{s3_part_prefix}/{name}")
        logging.info(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: s3://{bucket}/{s3_part_prefix}/ (pklâ†’faiss)")
    else:
        logging.warning("âš ï¸ ì—…ë¡œë“œí•  ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    shutil.rmtree(work_dir, ignore_errors=True)
    return used_urls


# -------------------------------
# Prewarm trigger
# -------------------------------
def trigger_prewarm_partition10(concurrency: int = 3, limit: int = 0, s3_prefix_base: str = "feature_faiss_db_openai_partition/", urls: Optional[List[str]] = None) -> int:
    repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
    cmd = [os.sys.executable, "-m", "fastapitest.scripts.prewarm_articles"]
    if urls:
        logging.info("ğŸ”¥ í”„ë¦¬ì›Œë° ëª¨ë“œ: file (urls=%d)", len(urls))
        # Write URLs to a temp file and use file mode to avoid title preloading duplication
        tmp_dir = os.path.join(repo_root, ".tmp")
        os.makedirs(tmp_dir, exist_ok=True)
        url_file = os.path.join(tmp_dir, f"urls_{TARGET_PARTITION}.txt")
        try:
            with open(url_file, "w", encoding="utf-8") as f:
                for u in urls:
                    f.write(u.strip() + "\n")
        except Exception as e:
            logging.error(f"URL íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return 1
        cmd += ["--source", "file", "--file", url_file]
    else:
        logging.info("ğŸ”¥ í”„ë¦¬ì›Œë° ëª¨ë“œ: partitions (prefix ê¸°ë°˜)")
        prefix = f"{s3_prefix_base.rstrip('/')}/{TARGET_PARTITION}/"
        cmd += ["--source", "partitions", "--prefix", prefix, "--force-reload"]
    cmd += ["--concurrency", str(concurrency), "--limit", str(limit)]
    logging.info(f"ğŸ§­ prewarm ì‹œì‘: {' '.join(cmd)} (cwd={repo_root})")
    proc = subprocess.run(cmd, capture_output=True, text=True, cwd=repo_root)
    if proc.returncode != 0:
        logging.error(f"âŒ prewarm ì‹¤íŒ¨(rc={proc.returncode})\nSTDOUT:\n{proc.stdout}\nSTDERR:\n{proc.stderr}")
    else:
        logging.info(f"âœ… prewarm ì™„ë£Œ\nSTDOUT:\n{proc.stdout}")
    return proc.returncode


# -------------------------------
# Entrypoint
# -------------------------------
def main():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    # Suppress noisy openpyxl default style warning
    warnings.filterwarnings(
        "ignore",
        message="Workbook contains no default style, apply openpyxl's default",
        category=UserWarning,
    )

    # ê³ ì • í…ŒìŠ¤íŠ¸ ê¸°ê°„(í™˜ê²½ë³€ìˆ˜ë¡œë„ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
    start_date = os.environ.get("TEST_START_DATE", "2025-08-26")
    end_date = os.environ.get("TEST_END_DATE", "2025-09-01")

    # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜
    user_id = os.environ.get("BIGKINDS_USER_ID")
    user_pw = os.environ.get("BIGKINDS_USER_PW")
    if not user_id or not user_pw:
        raise SystemExit("í™˜ê²½ë³€ìˆ˜ BIGKINDS_USER_ID/BIGKINDS_USER_PW í•„ìš”")

    openai_api_key = os.environ.get("OPENAI_API_KEY")
    if not openai_api_key:
        raise SystemExit("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=openai_api_key)

    # ì„ íƒ í™˜ê²½ ë³€ìˆ˜
    bucket = os.environ.get("S3_BUCKET_NAME", "factseeker-faiss-db")
    s3_prefix = os.environ.get("S3_INDEX_PREFIX", "feature_faiss_db_openai_partition/")
    download_dir = os.environ.get("DOWNLOAD_DIR", os.path.abspath("./downloads_test"))
    headless = os.environ.get("HEADLESS", "1") in ("1", "true", "TRUE", "yes", "YES")
    logging.info("ğŸ§¾ ì‹¤í–‰ íŒŒë¼ë¯¸í„°: bucket=%s, prefix=%s, download_dir=%s, headless=%s", bucket, s3_prefix, download_dir, headless)

    logging.info(f"í…ŒìŠ¤íŠ¸ ë²”ìœ„: {start_date} ~ {end_date} â†’ {TARGET_PARTITION}")

    # 1) BigKinds ë‹¤ìš´ë¡œë“œ
    downloaded = download_bigkinds_range(user_id, user_pw, start_date, end_date, download_dir, headless=headless)
    logging.info(f"ğŸ“¦ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ê²½ë¡œ: {downloaded}")

    # 2) CSV ë¡œì»¬ ì €ì¥(ì˜µì…˜, í•„ìˆ˜ ì»¬ëŸ¼ë§Œ) + ë¹Œë“œ/ì—…ë¡œë“œ
    df = pd.read_excel(downloaded)
    df.columns = [str(c).strip().replace("\n", "") for c in df.columns]
    logging.info("ğŸ§® ì—‘ì…€ ë¡œë“œ ì™„ë£Œ: rows=%d", len(df))
    write_csv = os.environ.get("WRITE_CSV", "1") in ("1", "true", "TRUE", "yes", "YES")
    if write_csv:
        csv_path = os.path.splitext(downloaded)[0] + ".csv"
        try:
            out = pd.DataFrame()
            for c in REQUIRED_CSV_COLUMNS:
                if c in df.columns:
                    out[c] = df[c]
                else:
                    out[c] = ""
            out = out.fillna("")
            out.to_csv(csv_path, index=False, encoding="utf-8-sig")
            logging.info("ğŸ“ CSV ë¡œì»¬ ì €ì¥ ì™„ë£Œ(í•„ìˆ˜ ì»¬ëŸ¼): %s", csv_path)
        except Exception as e:
            logging.warning("CSV ì €ì¥ ì‹¤íŒ¨(ê³„ì† ì§„í–‰): %s", e)
    used_urls = build_and_upload_partition10(df, embeddings, bucket, s3_prefix)

    # 3) prewarm íŠ¸ë¦¬ê±°(ìë™ í¬ë¡¤ë§)
    rc = trigger_prewarm_partition10(
        concurrency=int(os.environ.get("PREWARM_CONCURRENCY", "3")),
        limit=int(os.environ.get("PREWARM_LIMIT", "0")),
        s3_prefix_base=s3_prefix,
        urls=used_urls,
    )
    if rc != 0:
        raise SystemExit(rc)


if __name__ == "__main__":
    main()
