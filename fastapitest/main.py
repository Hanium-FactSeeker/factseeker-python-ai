import os
import asyncio
import json
import faiss
from shutil import rmtree # shutil ì„í¬íŠ¸ ì¶”ê°€
from langchain.docstore.document import Document
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# ì„œë¹„ìŠ¤ ë¡œì§ ì„í¬íŠ¸
from services.fact_checker import run_fact_check
from core.faiss_manager import CHUNK_CACHE_DIR
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from core.lambdas import clean_news_title, search_news_google_cs # í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° ì¶”ê°€
import logging
from core.faiss_manager import get_or_build_faiss
from core.preload_s3_faiss import preload_faiss_from_existing_s3

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)

app = FastAPI(
    title="YouTube Fact-Checker API",
    description="ìœ íŠœë¸Œ ì˜ìƒì˜ ì£¼ì¥ì„ íŒ©íŠ¸ì²´í¬í•˜ëŠ” API",
    version="1.0.0"
)

embed_model = OpenAIEmbeddings(
    model="text-embedding-3-small",
    request_timeout=60,
    max_retries=5,
    chunk_size=500
)

# ë¡œì»¬ ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
def clean_local_cache_dir():
    """CHUNK_CACHE_DIRì— ìˆëŠ” ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    logging.info(f"ğŸ§¹ ë¡œì»¬ ìºì‹œ ë””ë ‰í† ë¦¬ ({CHUNK_CACHE_DIR}) ì •ë¦¬ ì‹œì‘")
    if os.path.exists(CHUNK_CACHE_DIR):
        try:
            # os.makedirsë¥¼ ì‚¬ìš©í•œ ë””ë ‰í† ë¦¬ ìƒì„±ì€ ì¶”í›„ì— preload í•¨ìˆ˜ì—ì„œ ìˆ˜í–‰
            rmtree(CHUNK_CACHE_DIR)
            logging.info("âœ… ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        except OSError as e:
            logging.error(f"âŒ ìºì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
    else:
        logging.info("âœ… ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì´ë¯¸ ë¹„ì–´ìˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# FAISS DB ë° ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ì„œë²„ ì‹œì‘ ì‹œ)
@app.on_event("startup")
async def startup_event():
    logging.info("--- FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ---")

    # ì„œë²„ ì‹œì‘ ì‹œ ê°€ì¥ ë¨¼ì € ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    clean_local_cache_dir()

    # ë³¸ë¬¸ ì„ë² ë”© ìºì‹œ í”„ë¦¬ë¡œë“œ
    await preload_faiss_from_existing_s3("article_faiss_cache/")

    # (ì„ íƒ ì‚¬í•­) íŒŒí‹°ì…˜ ì „ì²´ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ë¡œë”©
    for i in range(10):
        prefix = f"feature_faiss_db_openai_partition/partition_{i}/"
        await preload_faiss_from_existing_s3(prefix)

    logging.info("âœ… ì „ì²´ FAISS í”„ë¦¬ë¡œë“œ ì™„ë£Œ")


class FactCheckRequest(BaseModel):
    youtube_url: str

class FactCheckResponse(BaseModel):
    video_id: str
    video_total_confidence_score: int
    claims: list


@app.post("/fact-check")
async def perform_fact_check(request: FactCheckRequest):
    """
    ì œê³µëœ ìœ íŠœë¸Œ URLì— ëŒ€í•´ íŒ©íŠ¸ì²´í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    logging.info(f"--- íŒ©íŠ¸ì²´í¬ ìš”ì²­ ìˆ˜ì‹ : {request.youtube_url} ---")
    try:
        logging.info("íŒ©íŠ¸ì²´í¬ ì‹œì‘...")
        result = await run_fact_check(request.youtube_url)
        if "error" in result:
            raise HTTPException(status_code=400, detail=result["error"])
        return result  # dict ì „ì²´ ê·¸ëŒ€ë¡œ ë°˜í™˜!
    except Exception as e:
        logging.exception(f"API ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"íŒ©íŠ¸ì²´í¬ ì²˜ë¦¬ ì¤‘ ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
